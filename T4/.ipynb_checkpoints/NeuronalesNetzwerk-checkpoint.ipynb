{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deep_cnn(features,labels, mode):\n",
    "    ####Input Layer \n",
    "    input_layer=tf.convert_to_tensor(features)\n",
    "    ####convolutional (random filters) and pooling (reduces szise) layers\n",
    "    #convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        data_format=\"channels_first\",\n",
    "        activation=tf.nn.relu)\n",
    "    #pooling layer #1\n",
    "    pool1 = tf.layers.average_pooling2d(\n",
    "        inputs=conv1,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2,\n",
    "        data_format=\"channels_first\")\n",
    "    #convolutional Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        data_format=\"channels_first\",\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    #pooling layer #2\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2,\n",
    "        data_format=\"channels_first\")\n",
    "    #convolutional Layer #3\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=128,\n",
    "        kernel_size=[3, 3],\n",
    "        data_format=\"channels_first\",\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    #pooling layer #3\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2,\n",
    "        data_format=\"channels_first\")\n",
    "    ####dense layers\n",
    "    #flatten pictures\n",
    "    pool3_flat=tf.reshape(pool3,[-1,pool3.shape[1]*pool3.shape[2]*pool3.shape[3]])\n",
    "    #dense layer #1\n",
    "    dense1 = tf.layers.dense(\n",
    "            inputs=pool3_flat,\n",
    "            units=256,\n",
    "            activation=tf.nn.relu)\n",
    "    #dropout to avoid overfitting\n",
    "    dropout1 = tf.layers.dropout(\n",
    "            inputs=dense1,\n",
    "            rate=0.4,\n",
    "            training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    #dense layer #2\n",
    "    dense2 = tf.layers.dense(\n",
    "            inputs=dropout1,\n",
    "            units=128,\n",
    "            activation=tf.nn.relu)\n",
    "    #dropout to avoid overfitting\n",
    "    dropout2 = tf.layers.dropout(\n",
    "            inputs=dense2,\n",
    "            rate=0.4,\n",
    "            training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    #final output dense layer\n",
    "    logits= tf.layers.dense(inputs=dense2, units=3)\n",
    "    ####predictions\n",
    "    #predictions as libarry\n",
    "    predictions = {\n",
    "        #makes predictions by highest output\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        #set logits to sum=1 (probabilitys)\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    ####Train and evaluate\n",
    "    # calculate loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    #training\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    #evaluation\n",
    "    eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 3, 32, 32) float32\n",
      "(6000,) int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"np.save('prediction.npy', prediction)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dateien laden und shufflen (shufflen ist6 immer gut)\n",
    "with np.load('prediction-challenge-02-data.npz') as fh:\n",
    "    data_shuffle_index=np.arange(6000)\n",
    "    np.random.shuffle(data_shuffle_index)\n",
    "    data_x = fh['data_x'][data_shuffle_index]\n",
    "    data_y = fh['data_y'][data_shuffle_index]\n",
    "    test_x = fh['test_x']\n",
    "\n",
    "# TRAINING DATA: INPUT (x) AND OUTPUT (y)\n",
    "# 1. INDEX: IMAGE SERIAL NUMBER (6000)\n",
    "# 2. INDEX: COLOR CHANNELS (3)\n",
    "# 3/4. INDEX: PIXEL VALUE (32 x 32)\n",
    "print(data_x.shape, data_x.dtype)\n",
    "print(data_y.shape, data_y.dtype)\n",
    "\n",
    "# TEST DATA: INPUT (x) ONLY\n",
    "\"\"\"print(test_x.shape, test_x.dtype)\"\"\"\n",
    "\n",
    "#Daten ausgeben\n",
    "# neuer shape mit (n,32,32,3) (plt.imshow compatibel)\n",
    "\"\"\"data_x=np.rollaxis(data_x,1,4)\n",
    "test_x=np.rollaxis(test_x,1,4)\"\"\"\n",
    "#n=0-6000\n",
    "\"\"\"n=5001\n",
    "plt.imshow(data_x[n])\"\"\"\n",
    "#titel beschreiben\n",
    "\"\"\"def tier(x):\n",
    "    if x==0:\n",
    "        return\"cat\"\n",
    "    elif x==1:\n",
    "        return\"dog\"\n",
    "    elif x==2:\n",
    "        return \"frog\"\n",
    "    else:\n",
    "        return\"error\"\n",
    "plt.title(tier(data_y[n]))\n",
    "plt.show()\"\"\"\n",
    "#generiere mehr testdaten\n",
    "\n",
    "\n",
    "############################################\n",
    "# TRAIN MODEL ON data_x, data_y\n",
    "\n",
    "# PREDICT prediction FROM test_x\n",
    "\n",
    "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
    "\"\"\"assert prediction.ndim == 1\n",
    "assert prediction.shape[0] == 300\"\"\"\n",
    "\n",
    "# AND SAVE EXACTLY AS SHOWN BELOW\n",
    "\"\"\"np.save('prediction.npy', prediction)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 32, 32)\n",
      "(4, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "test_cnn_x=data_x[0:4]\n",
    "test_cnn_y=data_y[0:4]\n",
    "print(test_cnn_x.shape)\n",
    "#Input Layer \n",
    "input_layer=tf.convert_to_tensor(test_cnn_x)\n",
    "print(input_layer.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+AmJlP8HuTO7X9R11WAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f9ad8d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_layer=tf.convert_to_tensor(test_x)\n",
    "\n",
    "n=0\n",
    "sess=tf.Session()\n",
    "a=sess.run(input_layer[n])\n",
    "a=np.rollaxis(a,0,3)\n",
    "\n",
    "print(a.shape)\n",
    "plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Input Layer \n",
    "input_layer=tf.convert_to_tensor(test_cnn_x)[0:2]\n",
    "#convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=30,\n",
    "    kernel_size=[5, 5],\n",
    "    data_format=\"channels_first\",\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "#pooling layer #1\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "    inputs=conv1, \n",
    "    pool_size=[2, 2],\n",
    "    strides=2,\n",
    "    data_format=\"channels_first\")\n",
    "#convolutional Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=30,\n",
    "    kernel_size=[3, 3],\n",
    "    data_format=\"channels_first\",\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "#pooling layer #2\n",
    "pool2 = tf.layers.max_pooling2d(\n",
    "    inputs=conv2,\n",
    "    pool_size=[2, 2],\n",
    "    strides=2,\n",
    "    data_format=\"channels_first\")\n",
    "#convolutional Layer #3\n",
    "conv3 = tf.layers.conv2d(\n",
    "    inputs=pool2,\n",
    "    filters=32,\n",
    "    kernel_size=[3, 3],\n",
    "    data_format=\"channels_first\",\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "#pooling layer #3\n",
    "pool3 = tf.layers.max_pooling2d(\n",
    "    inputs=conv3,\n",
    "    pool_size=[2, 2],\n",
    "    strides=2,\n",
    "    data_format=\"channels_first\")\n",
    "\n",
    "mode=tf.estimator.ModeKeys.PREDICT\n",
    "\n",
    "#dense layers\n",
    "#flatten pictures\n",
    "pool3_flat=tf.reshape(pool3,[-1,pool3.shape[1]*pool3.shape[2]*pool3.shape[3]])\n",
    "#dense layer #1\n",
    "dense1 = tf.layers.dense(\n",
    "        inputs=pool3_flat,\n",
    "        units=256,\n",
    "        activation=tf.nn.relu)\n",
    "#dropout to avoid overfitting\n",
    "dropout1 = tf.layers.dropout(\n",
    "        inputs=dense1,\n",
    "        rate=0.4,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "#dense layer #2\n",
    "dense2 = tf.layers.dense(\n",
    "        inputs=dropout1,\n",
    "        units=128,\n",
    "        activation=tf.nn.relu)\n",
    "#dropout to avoid overfitting\n",
    "dropout2 = tf.layers.dropout(\n",
    "        inputs=dense2,\n",
    "        rate=0.4,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "#final output dense layer\n",
    "logits= tf.layers.dense(inputs=dense2, units=3)\n",
    "\n",
    "\n",
    "predictions = {\n",
    "    #makes predictions by highest output\n",
    "    \"classes\": tf.argmax(input=logits, axis=1),\n",
    "    #set logits to sum=1 (probabilitys)\n",
    "    \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': <tf.Tensor 'ArgMax_3:0' shape=(2,) dtype=int64>,\n",
       " 'probabilities': <tf.Tensor 'softmax_tensor_3:0' shape=(2, 3) dtype=float32>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_25/Relu:0\", shape=(2, 30, 32, 32), dtype=float32)\n",
      "Tensor(\"max_pooling2d_25/MaxPool:0\", shape=(2, 30, 16, 16), dtype=float32)\n",
      "Tensor(\"conv2d_26/Relu:0\", shape=(2, 30, 16, 16), dtype=float32)\n",
      "Tensor(\"max_pooling2d_26/MaxPool:0\", shape=(2, 30, 8, 8), dtype=float32)\n",
      "Tensor(\"conv2d_27/Relu:0\", shape=(2, 32, 8, 8), dtype=float32)\n",
      "Tensor(\"max_pooling2d_27/MaxPool:0\", shape=(2, 32, 4, 4), dtype=float32)\n",
      "Tensor(\"Reshape_8:0\", shape=(2, 512), dtype=float32)\n",
      "Tensor(\"dense_21/Relu:0\", shape=(2, 256), dtype=float32)\n",
      "Tensor(\"dense_22/Relu:0\", shape=(2, 128), dtype=float32)\n",
      "Tensor(\"dropout_6/dropout/mul:0\", shape=(2, 128), dtype=float32)\n",
      "Tensor(\"dense_23/BiasAdd:0\", shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(conv1)\n",
    "print(pool1)\n",
    "print(conv2)\n",
    "print(pool2)\n",
    "print(conv3)\n",
    "print(pool3)\n",
    "print(pool3_flat)\n",
    "print(dense1)\n",
    "print(dense2)\n",
    "print(dropout2)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
