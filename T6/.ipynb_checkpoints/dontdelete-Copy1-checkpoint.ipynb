{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "\n",
    "if not os.path.exists('./img'):\n",
    "    os.mkdir('./img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 28 * 28),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        output = self.decoder(encoded)\n",
    "        return output\n",
    "    \n",
    "def add_noise(img,sigma=0.4):\n",
    "    noise = torch.randn(img.size()) * sigma\n",
    "    noisy_img = img + noise\n",
    "    return noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09ad0cc7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"np.save('test_images_clean.npy', test_images_clean)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with np.load('denoising-challenge-01-data.npz') as fh:\n",
    "    training_images_clean = torch.tensor(fh['training_images_clean']).view(20000,28*28)\n",
    "    validation_images_noisy = torch.tensor(fh['validation_images_noisy']).view(2000,28*28)\n",
    "    validation_images_clean = torch.tensor(fh['validation_images_clean']).view(2000,28*28)\n",
    "    test_images_noisy = torch.tensor(fh['test_images_noisy']).view(2000,28*28)\n",
    "    \n",
    "\n",
    "# TRAINING DATA: CLEAN\n",
    "# 1. INDEX: IMAGE SERIAL NUMBER (20000)\n",
    "# 2. INDEX: COLOR CHANNEL (1)\n",
    "# 3/4. INDEX: PIXEL VALUE (28 x 28)\n",
    "\"\"\"print(training_images_clean.shape, training_images_clean.dtype)\"\"\"\n",
    "# VALIDATION DATA: CLEAN + NOISY\n",
    "\"\"\"print(validation_images_clean.shape, validation_images_clean.dtype)\n",
    "print(validation_images_noisy.shape, validation_images_noisy.dtype)\"\"\"\n",
    "# TEST DATA: NOISY\n",
    "\"\"\"print(test_images_noisy.shape, test_images_noisy.dtype)\"\"\"\n",
    "\n",
    "#Daten ausgeben\n",
    "#n=(0,19999)\n",
    "\"\"\"n=19\n",
    "test=training_images_clean\"\"\"\n",
    "#n=(0,1999)\n",
    "\"\"\"n=5\n",
    "test=validation_images_noisy\"\"\"\n",
    "#n=(0,1999)\n",
    "\"\"\"n=1999\n",
    "test=validation_images_clean\"\"\"\n",
    "#n=(0,1999)\n",
    "n=1999\n",
    "test=test_images_noisy\n",
    "plt.figure\n",
    "plt.imshow(test[n].view(28,28),cmap='gray')\n",
    "plt.show()\n",
    "# TRAIN MODEL ON training_images_clean\n",
    "\n",
    "print('Finished Training')\n",
    "# CHECK YOUR MODEL USING (validation_images_clean, validation_images_noisy)\n",
    "\n",
    "# DENOISE IMAGES (test_images_clean) USING test_images_noisy\n",
    "\n",
    "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
    "\"\"\"assert test_images_clean.ndim == 4\n",
    "assert test_images_clean.shape[0] == 2000\n",
    "assert test_images_clean.shape[1] == 1\n",
    "assert test_images_clean.shape[2] == 28\n",
    "assert test_images_clean.shape[3] == 28\"\"\"\n",
    "\n",
    "# AND SAVE EXACTLY AS SHOWN BELOW\n",
    "\"\"\"np.save('test_images_clean.npy', test_images_clean)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/schuch/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 0.0455\n",
      "====> Epoch: 1 Average loss: 0.0299\n",
      "====> Epoch: 2 Average loss: 0.0219\n",
      "====> Epoch: 3 Average loss: 0.0235\n",
      "====> Epoch: 4 Average loss: 0.0168\n",
      "====> Epoch: 5 Average loss: 0.0183\n",
      "====> Epoch: 6 Average loss: 0.0155\n",
      "====> Epoch: 7 Average loss: 0.0148\n",
      "====> Epoch: 8 Average loss: 0.0138\n",
      "====> Epoch: 9 Average loss: 0.0130\n",
      "====> Epoch: 10 Average loss: 0.0130\n",
      "====> Epoch: 11 Average loss: 0.0100\n",
      "====> Epoch: 12 Average loss: 0.0116\n",
      "====> Epoch: 13 Average loss: 0.0118\n",
      "====> Epoch: 14 Average loss: 0.0098\n",
      "====> Epoch: 15 Average loss: 0.0112\n",
      "====> Epoch: 16 Average loss: 0.0131\n",
      "====> Epoch: 17 Average loss: 0.0103\n",
      "====> Epoch: 18 Average loss: 0.0089\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL ON training_images_clean\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "autoencoder = AutoEncoder()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "train_loader = DataLoader(dataset=training_images_clean, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        img = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        # ===================forward=====================\n",
    "        output = autoencoder(img)\n",
    "        loss = loss_func(output,img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ====================log========================\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, loss.data[0]))\n",
    "    if epoch % 10 == 0:\n",
    "        save = output.view(output.size(0), 1, 28, 28)\n",
    "        save_image(save, './img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(autoencoder.state_dict(), './autoencoder.pth')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
