{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "\n",
    "if not os.path.exists('./img'):\n",
    "    os.mkdir('./img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 28 * 28),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        output = self.decoder(encoded)\n",
    "        return output\n",
    "    \n",
    "def add_noise(img,sigma):\n",
    "    noise = torch.normal(0,std=torch.ones_like(img)) * sigma\n",
    "    return img + noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/schuch/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 0.0397\n",
      "====> Epoch: 1 Average loss: 0.0264\n",
      "====> Epoch: 2 Average loss: 0.0233\n",
      "====> Epoch: 3 Average loss: 0.0194\n",
      "====> Epoch: 4 Average loss: 0.0173\n",
      "====> Epoch: 5 Average loss: 0.0145\n",
      "====> Epoch: 6 Average loss: 0.0145\n",
      "====> Epoch: 7 Average loss: 0.0129\n",
      "====> Epoch: 8 Average loss: 0.0117\n",
      "====> Epoch: 9 Average loss: 0.0132\n",
      "====> Epoch: 10 Average loss: 0.0118\n",
      "====> Epoch: 11 Average loss: 0.0139\n",
      "====> Epoch: 12 Average loss: 0.0140\n",
      "====> Epoch: 13 Average loss: 0.0127\n",
      "====> Epoch: 14 Average loss: 0.0105\n",
      "====> Epoch: 15 Average loss: 0.0117\n",
      "====> Epoch: 16 Average loss: 0.0111\n",
      "====> Epoch: 17 Average loss: 0.0107\n",
      "====> Epoch: 18 Average loss: 0.0108\n",
      "====> Epoch: 19 Average loss: 0.0105\n",
      "====> Epoch: 20 Average loss: 0.0102\n",
      "====> Epoch: 21 Average loss: 0.0099\n",
      "====> Epoch: 22 Average loss: 0.0110\n",
      "====> Epoch: 23 Average loss: 0.0108\n",
      "====> Epoch: 24 Average loss: 0.0114\n",
      "====> Epoch: 25 Average loss: 0.0092\n",
      "====> Epoch: 26 Average loss: 0.0096\n",
      "====> Epoch: 27 Average loss: 0.0102\n",
      "====> Epoch: 28 Average loss: 0.0098\n",
      "====> Epoch: 29 Average loss: 0.0097\n",
      "====> Epoch: 30 Average loss: 0.0106\n",
      "====> Epoch: 31 Average loss: 0.0099\n",
      "====> Epoch: 32 Average loss: 0.0111\n",
      "====> Epoch: 33 Average loss: 0.0088\n",
      "====> Epoch: 34 Average loss: 0.0106\n",
      "====> Epoch: 35 Average loss: 0.0090\n",
      "====> Epoch: 36 Average loss: 0.0090\n",
      "====> Epoch: 37 Average loss: 0.0098\n",
      "====> Epoch: 38 Average loss: 0.0095\n",
      "====> Epoch: 39 Average loss: 0.0110\n",
      "====> Epoch: 40 Average loss: 0.0095\n",
      "====> Epoch: 41 Average loss: 0.0107\n",
      "====> Epoch: 42 Average loss: 0.0090\n",
      "====> Epoch: 43 Average loss: 0.0095\n",
      "====> Epoch: 44 Average loss: 0.0092\n",
      "====> Epoch: 45 Average loss: 0.0077\n",
      "====> Epoch: 46 Average loss: 0.0096\n",
      "====> Epoch: 47 Average loss: 0.0085\n",
      "====> Epoch: 48 Average loss: 0.0077\n",
      "====> Epoch: 49 Average loss: 0.0098\n",
      "====> Epoch: 50 Average loss: 0.0094\n",
      "====> Epoch: 51 Average loss: 0.0080\n",
      "====> Epoch: 52 Average loss: 0.0088\n",
      "====> Epoch: 53 Average loss: 0.0097\n",
      "====> Epoch: 54 Average loss: 0.0089\n",
      "====> Epoch: 55 Average loss: 0.0081\n",
      "====> Epoch: 56 Average loss: 0.0090\n",
      "====> Epoch: 57 Average loss: 0.0087\n",
      "====> Epoch: 58 Average loss: 0.0102\n",
      "====> Epoch: 59 Average loss: 0.0085\n",
      "====> Epoch: 60 Average loss: 0.0087\n",
      "====> Epoch: 61 Average loss: 0.0089\n",
      "====> Epoch: 62 Average loss: 0.0081\n",
      "====> Epoch: 63 Average loss: 0.0085\n",
      "====> Epoch: 64 Average loss: 0.0080\n",
      "====> Epoch: 65 Average loss: 0.0086\n",
      "====> Epoch: 66 Average loss: 0.0081\n",
      "====> Epoch: 67 Average loss: 0.0083\n",
      "====> Epoch: 68 Average loss: 0.0096\n",
      "====> Epoch: 69 Average loss: 0.0084\n",
      "====> Epoch: 70 Average loss: 0.0087\n",
      "====> Epoch: 71 Average loss: 0.0099\n",
      "====> Epoch: 72 Average loss: 0.0085\n",
      "====> Epoch: 73 Average loss: 0.0085\n",
      "====> Epoch: 74 Average loss: 0.0104\n",
      "====> Epoch: 75 Average loss: 0.0099\n",
      "====> Epoch: 76 Average loss: 0.0089\n",
      "====> Epoch: 77 Average loss: 0.0079\n",
      "====> Epoch: 78 Average loss: 0.0089\n",
      "====> Epoch: 79 Average loss: 0.0092\n",
      "====> Epoch: 80 Average loss: 0.0082\n",
      "====> Epoch: 81 Average loss: 0.0084\n",
      "====> Epoch: 82 Average loss: 0.0089\n",
      "====> Epoch: 83 Average loss: 0.0069\n",
      "====> Epoch: 84 Average loss: 0.0074\n",
      "====> Epoch: 85 Average loss: 0.0079\n",
      "====> Epoch: 86 Average loss: 0.0086\n",
      "====> Epoch: 87 Average loss: 0.0071\n",
      "====> Epoch: 88 Average loss: 0.0080\n",
      "====> Epoch: 89 Average loss: 0.0067\n",
      "====> Epoch: 90 Average loss: 0.0081\n",
      "====> Epoch: 91 Average loss: 0.0082\n",
      "====> Epoch: 92 Average loss: 0.0083\n",
      "====> Epoch: 93 Average loss: 0.0072\n",
      "====> Epoch: 94 Average loss: 0.0076\n",
      "====> Epoch: 95 Average loss: 0.0086\n",
      "====> Epoch: 96 Average loss: 0.0087\n",
      "====> Epoch: 97 Average loss: 0.0093\n",
      "====> Epoch: 98 Average loss: 0.0078\n",
      "====> Epoch: 99 Average loss: 0.0080\n",
      "====> Epoch: 100 Average loss: 0.0079\n",
      "====> Epoch: 101 Average loss: 0.0077\n",
      "====> Epoch: 102 Average loss: 0.0093\n",
      "====> Epoch: 103 Average loss: 0.0083\n",
      "====> Epoch: 104 Average loss: 0.0074\n",
      "====> Epoch: 105 Average loss: 0.0080\n",
      "====> Epoch: 106 Average loss: 0.0086\n",
      "====> Epoch: 107 Average loss: 0.0071\n",
      "====> Epoch: 108 Average loss: 0.0085\n",
      "====> Epoch: 109 Average loss: 0.0073\n",
      "====> Epoch: 110 Average loss: 0.0082\n",
      "====> Epoch: 111 Average loss: 0.0087\n",
      "====> Epoch: 112 Average loss: 0.0080\n",
      "====> Epoch: 113 Average loss: 0.0082\n",
      "====> Epoch: 114 Average loss: 0.0072\n",
      "====> Epoch: 115 Average loss: 0.0078\n",
      "====> Epoch: 116 Average loss: 0.0075\n",
      "====> Epoch: 117 Average loss: 0.0081\n",
      "====> Epoch: 118 Average loss: 0.0084\n",
      "====> Epoch: 119 Average loss: 0.0091\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/schuch/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> validation: Average loss: 0.0081\n"
     ]
    }
   ],
   "source": [
    "with np.load('denoising-challenge-01-data.npz') as fh:\n",
    "    training_images_clean = torch.tensor(fh['training_images_clean']).view(20000,28*28)\n",
    "    validation_images_noisy = torch.tensor(fh['validation_images_noisy']).view(2000,28*28)\n",
    "    validation_images_clean = torch.tensor(fh['validation_images_clean']).view(2000,28*28)\n",
    "    test_images_noisy = torch.tensor(fh['test_images_noisy']).view(2000,28*28)\n",
    "    \n",
    "\n",
    "# TRAINING DATA: CLEAN\n",
    "# 1. INDEX: IMAGE SERIAL NUMBER (20000)\n",
    "# 2. INDEX: COLOR CHANNEL (1)\n",
    "# 3/4. INDEX: PIXEL VALUE (28 x 28)\n",
    "\"\"\"print(training_images_clean.shape, training_images_clean.dtype)\"\"\"\n",
    "# VALIDATION DATA: CLEAN + NOISY\n",
    "\"\"\"print(validation_images_clean.shape, validation_images_clean.dtype)\n",
    "print(validation_images_noisy.shape, validation_images_noisy.dtype)\"\"\"\n",
    "# TEST DATA: NOISY\n",
    "\"\"\"print(test_images_noisy.shape, test_images_noisy.dtype)\"\"\"\n",
    "\n",
    "#Daten ausgeben\n",
    "#n=(0,19999)\n",
    "\"\"\"n=19\n",
    "test=training_images_clean\"\"\"\n",
    "#n=(0,1999)\n",
    "\"\"\"n=5\n",
    "test=validation_images_noisy\"\"\"\n",
    "#n=(0,1999)\n",
    "\"\"\"n=1999\n",
    "test=validation_images_clean\"\"\"\n",
    "#n=(0,1999)\n",
    "\"\"\"n=1999\n",
    "test=test_images_noisy\"\"\"\n",
    "\"\"\"plt.figure\n",
    "plt.imshow(test[n].view(28,28),cmap='gray')\n",
    "plt.show()\"\"\"\n",
    "\n",
    "# TRAIN MODEL ON training_images_clean\n",
    "num_epochs = 120\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "standard_deviation=(validation_images_noisy-validation_images_clean).std(dim=1)\n",
    "sigma=standard_deviation.sum()/standard_deviation.shape[0]\n",
    "\n",
    "autoencoder = AutoEncoder()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "train_loader = DataLoader(dataset=training_images_clean, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        img = data\n",
    "        noisy_img = add_noise(img,sigma)\n",
    "        # ===================forward=====================\n",
    "        output = autoencoder(noisy_img)\n",
    "        loss = loss_func(output,img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ====================log========================\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, loss.data[0]))\n",
    "    if epoch % 10 == 0:\n",
    "        save_in = img.view(output.size(0), 1, 28, 28)\n",
    "        save_out = output.view(output.size(0), 1, 28, 28)\n",
    "        save_image(save_in, './img/image_{}_in.png'.format(epoch))\n",
    "        save_image(save_out, './img/image_{}_out.png'.format(epoch))\n",
    "\n",
    "torch.save(autoencoder.state_dict(), './autoencoder.pth')\n",
    "print('Finished Training')\n",
    "# CHECK YOUR MODEL USING (validation_images_clean, validation_images_noisy)\n",
    "with torch.no_grad():\n",
    "    output=autoencoder(validation_images_noisy)\n",
    "    fehler = ((((output-validation_images_clean)**2).sum())**(1/2))/2000\n",
    "    print('====> validation: Average loss: {:.4f}'.format(\n",
    "        fehler))\n",
    "save_in = validation_images_clean.view(validation_images_clean.size(0), 1, 28, 28)\n",
    "save_out = output.view(output.shape[0],1,28,28)\n",
    "save_image(save_in, './img/image_val_in.png')\n",
    "save_image(save_out, './img/image_val_out.png')\n",
    "# DENOISE IMAGES (test_images_clean) USING test_images_noisy\n",
    "with torch.no_grad():\n",
    "    test_images_clean=autoencoder(test_images_noisy)\n",
    "save_in = test_images_noisy.view(test_images_noisy.shape[0], 1, 28, 28)\n",
    "save_out = test_images_clean.view(test_images_clean.shape[0],1,28,28)\n",
    "save_image(save_in, './img/image_denoised_in.png')\n",
    "save_image(save_out, './img/image_denoised_out.png')\n",
    "test_images_clean=test_images_clean.view(test_images_clean.shape[0],1,28,28).numpy()\n",
    "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
    "assert test_images_clean.ndim == 4\n",
    "assert test_images_clean.shape[0] == 2000\n",
    "assert test_images_clean.shape[1] == 1\n",
    "assert test_images_clean.shape[2] == 28\n",
    "assert test_images_clean.shape[3] == 28\n",
    "\n",
    "# AND SAVE EXACTLY AS SHOWN BELOW\n",
    "np.save('test_images_clean.npy', test_images_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> validation: Average loss: 0.0564\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output=autoencoder(validation_images_noisy)\n",
    "    fehler = ((((output-validation_images_clean)**2).sum())**(1/2))/2000\n",
    "    print('====> validation: Average loss: {:.4f}'.format(\n",
    "        fehler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
